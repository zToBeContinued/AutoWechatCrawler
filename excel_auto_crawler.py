# coding:utf-8
# excel_auto_crawler.py
import pandas as pd
import logging
import time
import os
import json
from read_cookie import ReadCookie
from batch_readnum_spider import BatchReadnumSpider
from wechat_browser_automation import WeChatBrowserAutomation, UI_AUTOMATION_AVAILABLE

class ExcelAutoCrawler:
    def __init__(self, excel_path="target_articles.xlsx"):
        self.excel_path = excel_path
        self.logger = logging.getLogger()
        
        if not UI_AUTOMATION_AVAILABLE:
            raise ImportError("UIè‡ªåŠ¨åŒ–åº“ 'uiautomation' æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ã€‚")
            
        self.automation = WeChatBrowserAutomation()
        # ä½¿ç”¨æ—§ç‰ˆReadCookieï¼Œä½†ä¸åˆ é™¤ç°æœ‰æ–‡ä»¶ï¼ˆç”¨äºéªŒè¯ç°æœ‰Cookieï¼‰
        self.cookie_reader = ReadCookie(outfile="wechat_keys.txt", delete_existing_file=False)
        self.spider = BatchReadnumSpider()

    def _get_target_url_from_excel(self) -> str:
        # ... (æ­¤æ–¹æ³•ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œæ— éœ€ä¿®æ”¹)
        self.logger.info(f"æ­£åœ¨ä» {self.excel_path} è¯»å–ç›®æ ‡URL...")
        if not os.path.exists(self.excel_path):
            self.logger.error(f"Excelæ–‡ä»¶æœªæ‰¾åˆ°: {self.excel_path}")
            return None
        try:
            df = pd.read_excel(self.excel_path)
            url_column = 'æ–‡ç« é“¾æ¥' if 'æ–‡ç« é“¾æ¥' in df.columns else 'url'
            if url_column not in df.columns:
                self.logger.error("Excelä¸­æœªæ‰¾åˆ° 'æ–‡ç« é“¾æ¥' æˆ– 'url' åˆ—ã€‚")
                return None
            for url in df[url_column]:
                if pd.notna(url) and 'mp.weixin.qq.com' in str(url):
                    self.logger.info(f"æˆåŠŸè¯»å–åˆ°ç›®æ ‡URL: {url[:50]}...")
                    return str(url)
            self.logger.error("Excelä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å¾®ä¿¡æ–‡ç« é“¾æ¥ã€‚")
            return None
        except Exception as e:
            self.logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            return None

    def _get_all_target_urls_from_excel(self) -> list:
        """
        ä»Excelæ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰æœ‰æ•ˆçš„å…¬ä¼—å·é“¾æ¥
        :return: åŒ…å«æ‰€æœ‰æœ‰æ•ˆé“¾æ¥å’Œå…¬ä¼—å·åç§°çš„åˆ—è¡¨
        """
        self.logger.info(f"æ­£åœ¨ä» {self.excel_path} è¯»å–æ‰€æœ‰ç›®æ ‡URL...")
        if not os.path.exists(self.excel_path):
            self.logger.error(f"Excelæ–‡ä»¶æœªæ‰¾åˆ°: {self.excel_path}")
            return []

        try:
            df = pd.read_excel(self.excel_path)
            url_column = 'æ–‡ç« é“¾æ¥' if 'æ–‡ç« é“¾æ¥' in df.columns else 'url'
            name_column = 'å…¬ä¼—å·åç§°' if 'å…¬ä¼—å·åç§°' in df.columns else 'name'

            if url_column not in df.columns:
                self.logger.error("Excelä¸­æœªæ‰¾åˆ° 'æ–‡ç« é“¾æ¥' æˆ– 'url' åˆ—ã€‚")
                return []

            valid_targets = []
            for index, row in df.iterrows():
                url = row[url_column]
                name = row.get(name_column, f"å…¬ä¼—å·_{index+1}") if name_column in df.columns else f"å…¬ä¼—å·_{index+1}"

                if pd.notna(url) and 'mp.weixin.qq.com' in str(url):
                    valid_targets.append({
                        'name': str(name),
                        'url': str(url),
                        'index': index + 1
                    })
                    self.logger.info(f"æ‰¾åˆ°æœ‰æ•ˆç›®æ ‡ {index+1}: {name} - {str(url)[:50]}...")

            self.logger.info(f"å…±æ‰¾åˆ° {len(valid_targets)} ä¸ªæœ‰æ•ˆçš„å…¬ä¼—å·ç›®æ ‡")
            return valid_targets

        except Exception as e:
            self.logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _get_new_cookie_via_automation(self, target_url=None) -> bool:
        """
        æ ¸å¿ƒæµç¨‹ï¼šå¯åŠ¨æŠ“å–å™¨ï¼ŒUIè‡ªåŠ¨åŒ–æ‰“å¼€é“¾æ¥ï¼Œç­‰å¾…Cookieï¼Œåœæ­¢æŠ“å–å™¨ã€‚
        :param target_url: æŒ‡å®šçš„ç›®æ ‡URLï¼Œå¦‚æœä¸ºNoneåˆ™ä»Excelè¯»å–ç¬¬ä¸€ä¸ª
        """
        if target_url is None:
            target_url = self._get_target_url_from_excel()

        if not target_url:
            return False

        # ä¸ºé‡æ–°æŠ“å–Cookieåˆ›å»ºæ–°çš„ReadCookieå®ä¾‹ï¼Œåˆ é™¤æ—§æ–‡ä»¶
        fresh_cookie_reader = ReadCookie(outfile="wechat_keys.txt", delete_existing_file=True)

        self.logger.info("å¯åŠ¨mitmproxyæŠ“å–å™¨...")
        if not fresh_cookie_reader.start_cookie_extractor():
            self.logger.error("mitmproxyæŠ“å–å™¨å¯åŠ¨å¤±è´¥ã€‚")
            return False

        self.logger.info("æŠ“å–å™¨å·²åœ¨åå°å¯åŠ¨ï¼Œç°åœ¨å¼€å§‹æ‰§è¡Œå¾®ä¿¡UIè‡ªåŠ¨åŒ–...")

        # è°ƒç”¨UIè‡ªåŠ¨åŒ–å‘é€å¹¶ç‚¹å‡»é“¾æ¥ï¼Œä¼ é€’fresh_cookie_readerä»¥å¯ç”¨æ™ºèƒ½åˆ·æ–°åœæ­¢
        success = self.automation.send_and_open_latest_link(target_url, cookie_reader=fresh_cookie_reader)

        if not success:
            self.logger.error("UIè‡ªåŠ¨åŒ–æ“ä½œå¤±è´¥ï¼Œæœªèƒ½æˆåŠŸç‚¹å‡»é“¾æ¥ã€‚")
            fresh_cookie_reader.stop_cookie_extractor()
            return False

        self.logger.info("UIè‡ªåŠ¨åŒ–æ“ä½œæˆåŠŸï¼Œç­‰å¾…Cookieè¢«æŠ“å–...")

        # ç­‰å¾…mitmproxyæŠ“å–åˆ°æ–°çš„cookie
        if fresh_cookie_reader.wait_for_new_cookie(timeout=60):
            self.logger.info("âœ… æˆåŠŸæŠ“å–åˆ°æ–°çš„Cookieï¼")
            fresh_cookie_reader.stop_cookie_extractor()
            return True
        else:
            self.logger.error("âŒ CookieæŠ“å–è¶…æ—¶æˆ–å¤±è´¥ã€‚")
            fresh_cookie_reader.stop_cookie_extractor()
            return False

    def open_wechat_and_trigger_url(self) -> bool:
        """
        ä»…æ‰§è¡ŒUIè‡ªåŠ¨åŒ–éƒ¨åˆ†ï¼šæ‰“å¼€å¾®ä¿¡ï¼Œå‘é€å¹¶ç‚¹å‡»é“¾æ¥ä»¥è§¦å‘mitmproxyæŠ“å–ã€‚
        ä¸åŒ…å«å¯åŠ¨æˆ–åœæ­¢mitmproxyçš„é€»è¾‘ã€‚
        """
        target_url = self._get_target_url_from_excel()
        if not target_url:
            return False

        self.logger.info("æ­£åœ¨æ‰§è¡Œå¾®ä¿¡UIè‡ªåŠ¨åŒ–ï¼Œå‘é€å¹¶æ‰“å¼€é“¾æ¥...")
        success = self.automation.send_and_open_latest_link(target_url, cookie_reader=self.cookie_reader)
        
        if not success:
            self.logger.error("UIè‡ªåŠ¨åŒ–æ“ä½œå¤±è´¥ï¼Œæœªèƒ½æˆåŠŸç‚¹å‡»é“¾æ¥ã€‚")
            return False
            
        self.logger.info("UIè‡ªåŠ¨åŒ–æ“ä½œæˆåŠŸï¼Œé“¾æ¥å·²åœ¨å¾®ä¿¡å†…ç½®æµè§ˆå™¨ä¸­æ‰“å¼€ã€‚")
        return True

    def auto_crawl_from_excel(self):
        """
        ã€å‡çº§ç‰ˆã€‘æ‰§è¡Œä»Excelå¯åŠ¨çš„å…¨è‡ªåŠ¨çˆ¬å–æµç¨‹ï¼Œæ”¯æŒå¤šä¸ªå…¬ä¼—å·ã€‚
        æ­¤æ–¹æ³•ä¼šå¾ªç¯å¤„ç†Excelä¸­çš„æ‰€æœ‰å…¬ä¼—å·é“¾æ¥ã€‚
        """
        self.logger.info("="*80)
        self.logger.info("ğŸš€ å¯åŠ¨Excelå¤šå…¬ä¼—å·å…¨è‡ªåŠ¨çˆ¬å–æµç¨‹")
        self.logger.info("="*80)

        # è·å–æ‰€æœ‰ç›®æ ‡å…¬ä¼—å·
        all_targets = self._get_all_target_urls_from_excel()
        if not all_targets:
            self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å…¬ä¼—å·é“¾æ¥ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œã€‚")
            return

        self.logger.info(f"ğŸ“‹ å…±æ‰¾åˆ° {len(all_targets)} ä¸ªå…¬ä¼—å·ï¼Œå¼€å§‹é€ä¸ªå¤„ç†...")

        # ç”¨äºå­˜å‚¨æ‰€æœ‰å…¬ä¼—å·çš„æŠ“å–ç»“æœ
        all_results = []
        successful_count = 0
        failed_count = 0

        for i, target in enumerate(all_targets, 1):
            self.logger.info("="*60)
            self.logger.info(f"ğŸ“ å¤„ç†ç¬¬ {i}/{len(all_targets)} ä¸ªå…¬ä¼—å·: {target['name']}")
            self.logger.info("="*60)

            try:
                # æ­¥éª¤1: ä¸ºå½“å‰å…¬ä¼—å·è·å–Cookie
                self.logger.info(f"[æ­¥éª¤ 1/2] ä¸º '{target['name']}' è·å–æœ€æ–°Cookie...")
                if not self._get_new_cookie_via_automation(target['url']):
                    self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' Cookieè·å–å¤±è´¥ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
                    failed_count += 1
                    continue

                # æ­¥éª¤2: ä½¿ç”¨æ–°Cookieæ‰¹é‡çˆ¬å–æ–‡ç« 
                self.logger.info(f"[æ­¥éª¤ 2/2] ä½¿ç”¨æ–°Cookieçˆ¬å– '{target['name']}' çš„æ–‡ç« ...")

                # ä½¿ç”¨get_latest_cookiesè·å–è§£æåçš„æ•°æ®
                cookie_data = self.cookie_reader.get_latest_cookies()
                if not cookie_data:
                    self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' Cookieæ•°æ®è§£æå¤±è´¥")
                    self.logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› :")
                    self.logger.error("   1. mitmproxy æ²¡æœ‰æˆåŠŸæŠ“å–åˆ°å¾®ä¿¡è¯·æ±‚")
                    self.logger.error("   2. å¾®ä¿¡å†…ç½®æµè§ˆå™¨æ²¡æœ‰æ­£ç¡®æ‰“å¼€é“¾æ¥")
                    self.logger.error("   3. Cookieæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºç©º")
                    self.logger.error("ğŸ’¡ å»ºè®®:")
                    self.logger.error("   1. æ£€æŸ¥å¾®ä¿¡æ˜¯å¦æ­£å¸¸æ‰“å¼€äº†æ–‡ç« é“¾æ¥")
                    self.logger.error("   2. æ‰‹åŠ¨åœ¨å¾®ä¿¡ä¸­åˆ·æ–°æ–‡ç« é¡µé¢")
                    self.logger.error("   3. æ£€æŸ¥wechat_keys.txtæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«å®Œæ•´æ•°æ®")
                    failed_count += 1
                    continue

                # åˆ›å»ºæ–°çš„çˆ¬è™«å®ä¾‹ï¼ˆé¿å…æ•°æ®æ··æ·†ï¼‰
                current_spider = BatchReadnumSpider()
                current_spider.biz = cookie_data['biz']
                current_spider.appmsg_token = cookie_data['appmsg_token']
                current_spider.cookie_str = cookie_data['cookie_str']
                current_spider.headers['Cookie'] = cookie_data['cookie_str']

                # æ‰§è¡Œçˆ¬å–
                current_spider.batch_crawl_readnum(max_pages=3, days_back=7)

                if current_spider.articles_data:
                    # ä¸ºæ¯ç¯‡æ–‡ç« æ·»åŠ å…¬ä¼—å·ä¿¡æ¯
                    for article in current_spider.articles_data:
                        article['å…¬ä¼—å·åç§°'] = target['name']
                        article['å…¬ä¼—å·åºå·'] = i

                    all_results.extend(current_spider.articles_data)

                    # ä¿å­˜å½“å‰å…¬ä¼—å·çš„æ•°æ®
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    excel_file = current_spider.save_to_excel(f"./data/readnum_batch/readnum_{target['name']}_{timestamp}.xlsx")
                    json_file = current_spider.save_to_json(f"./data/readnum_batch/readnum_{target['name']}_{timestamp}.json")

                    self.logger.info(f"âœ… å…¬ä¼—å· '{target['name']}' çˆ¬å–å®Œæˆï¼è·å– {len(current_spider.articles_data)} ç¯‡æ–‡ç« ")
                    self.logger.info(f"ğŸ“Š æ•°æ®å·²ä¿å­˜åˆ°: {excel_file}")
                    successful_count += 1
                else:
                    self.logger.warning(f"âš ï¸ å…¬ä¼—å· '{target['name']}' æœªè·å–åˆ°ä»»ä½•æ–‡ç« æ•°æ®")
                    failed_count += 1

                # å…¬ä¼—å·é—´å»¶è¿Ÿï¼Œé¿å…é¢‘ç¹è¯·æ±‚
                if i < len(all_targets):
                    delay_time = 10
                    self.logger.info(f"â³ å…¬ä¼—å·é—´å»¶è¿Ÿ {delay_time} ç§’...")
                    time.sleep(delay_time)

            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†å…¬ä¼—å· '{target['name']}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                failed_count += 1
                continue

        # æ±‡æ€»ç»“æœ
        self.logger.info("="*80)
        self.logger.info("ğŸ“Š å¤šå…¬ä¼—å·çˆ¬å–æ±‡æ€»ç»“æœ")
        self.logger.info("="*80)
        self.logger.info(f"âœ… æˆåŠŸå¤„ç†: {successful_count} ä¸ªå…¬ä¼—å·")
        self.logger.info(f"âŒ å¤±è´¥å¤„ç†: {failed_count} ä¸ªå…¬ä¼—å·")
        self.logger.info(f"ğŸ“„ æ€»è®¡æ–‡ç« : {len(all_results)} ç¯‡")

        # æ±‡æ€»æ•°æ®ä¿å­˜åŠŸèƒ½å·²ç§»é™¤

        self.logger.info("="*80)
        self.logger.info("âœ… å¤šå…¬ä¼—å·å…¨è‡ªåŠ¨çˆ¬å–æµç¨‹æ‰§è¡Œå®Œæ¯•")
        self.logger.info("="*80)