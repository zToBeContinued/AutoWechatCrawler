# automated_crawler.py
"""
å…¨æ–°çš„å…¨è‡ªåŠ¨åŒ–çˆ¬è™«æ§åˆ¶å™¨ - æ”¯æŒå¤šå…¬ä¼—å·
"""
import logging
import time
import os
import json
import pandas as pd
from read_cookie import ReadCookie
from batch_readnum_spider import BatchReadnumSpider
from excel_auto_crawler import ExcelAutoCrawler
from database_manager import DatabaseManager
from database_config import get_database_config

class AutomatedCrawler:
    """
    åè°ƒæ•´ä¸ªè‡ªåŠ¨åŒ–æµç¨‹çš„æ§åˆ¶å™¨ - æ”¯æŒå¤šå…¬ä¼—å·:
    1. ä»Excelè¯»å–æ‰€æœ‰å…¬ä¼—å·é“¾æ¥
    2. å¯¹æ¯ä¸ªå…¬ä¼—å·æ‰§è¡Œå®Œæ•´çš„æŠ“å–æµç¨‹:
       - å¯åŠ¨ mitmproxy æŠ“å–å™¨ (ä¼šè‡ªåŠ¨è®¾ç½®ä»£ç†)
       - è¿è¡Œ UI è‡ªåŠ¨åŒ–æ‰“å¼€å¾®ä¿¡æ–‡ç« ä»¥è§¦å‘æŠ“å–
       - ç­‰å¾…å¹¶éªŒè¯ Cookie æ˜¯å¦æˆåŠŸæŠ“å–
       - åœæ­¢ mitmproxy æŠ“å–å™¨ (ä¼šè‡ªåŠ¨å…³é—­ä»£ç†)
       - ä½¿ç”¨è·å–åˆ°çš„ Cookie è¿è¡Œæ‰¹é‡çˆ¬è™«
    3. æ±‡æ€»æ‰€æœ‰å…¬ä¼—å·çš„æŠ“å–ç»“æœ
    """
    def __init__(self, excel_path="target_articles.xlsx", save_to_db=True, db_config=None):
        self.logger = logging.getLogger()
        self.excel_path = excel_path
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºcookie_readerï¼Œæ¯ä¸ªå…¬ä¼—å·å•ç‹¬åˆ›å»º

        # æ•°æ®åº“ç›¸å…³é…ç½®
        self.save_to_db = save_to_db
        self.db_config = db_config or get_database_config()

        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        if self.save_to_db:
            try:
                with DatabaseManager(**self.db_config) as db:
                    count = db.get_articles_count()
                    self.logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼å½“å‰æœ‰ {count} ç¯‡æ–‡ç« ")
            except Exception as e:
                self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
                self.logger.warning("âš ï¸ å°†åªä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“")
                self.save_to_db = False

    def _get_all_target_urls_from_excel(self) -> list:
        """
        ä»Excelæ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰æœ‰æ•ˆçš„å…¬ä¼—å·é“¾æ¥
        :return: åŒ…å«æ‰€æœ‰æœ‰æ•ˆé“¾æ¥å’Œå…¬ä¼—å·åç§°çš„åˆ—è¡¨
        """
        self.logger.info(f"æ­£åœ¨ä» {self.excel_path} è¯»å–æ‰€æœ‰ç›®æ ‡URL...")
        if not os.path.exists(self.excel_path):
            self.logger.error(f"Excelæ–‡ä»¶æœªæ‰¾åˆ°: {self.excel_path}")
            return []

        try:
            df = pd.read_excel(self.excel_path)
            url_column = 'æ–‡ç« é“¾æ¥' if 'æ–‡ç« é“¾æ¥' in df.columns else 'url'
            name_column = 'å…¬ä¼—å·åç§°' if 'å…¬ä¼—å·åç§°' in df.columns else 'name'

            if url_column not in df.columns:
                self.logger.error("Excelä¸­æœªæ‰¾åˆ° 'æ–‡ç« é“¾æ¥' æˆ– 'url' åˆ—ã€‚")
                return []

            valid_targets = []
            for index, row in df.iterrows():
                url = row[url_column]
                name = row.get(name_column, f"å…¬ä¼—å·_{index+1}") if name_column in df.columns else f"å…¬ä¼—å·_{index+1}"

                if pd.notna(url) and 'mp.weixin.qq.com' in str(url):
                    valid_targets.append({
                        'name': str(name),
                        'url': str(url),
                        'index': index + 1
                    })
                    self.logger.info(f"æ‰¾åˆ°æœ‰æ•ˆç›®æ ‡ {index+1}: {name} - {str(url)[:50]}...")

            self.logger.info(f"å…±æ‰¾åˆ° {len(valid_targets)} ä¸ªæœ‰æ•ˆçš„å…¬ä¼—å·ç›®æ ‡")
            return valid_targets

        except Exception as e:
            self.logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„å¤šå…¬ä¼—å·è‡ªåŠ¨åŒ–æµç¨‹"""
        self.logger.info("="*80)
        self.logger.info("ğŸš€ å¤šå…¬ä¼—å·å…¨æ–°è‡ªåŠ¨åŒ–æµç¨‹å¯åŠ¨ ğŸš€")
        self.logger.info("="*80)

        # è·å–æ‰€æœ‰ç›®æ ‡å…¬ä¼—å·
        all_targets = self._get_all_target_urls_from_excel()
        if not all_targets:
            self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å…¬ä¼—å·é“¾æ¥ï¼Œæµç¨‹ä¸­æ­¢ã€‚")
            return False

        self.logger.info(f"ğŸ“‹ å…±æ‰¾åˆ° {len(all_targets)} ä¸ªå…¬ä¼—å·ï¼Œå¼€å§‹é€ä¸ªå¤„ç†...")

        # ç”¨äºå­˜å‚¨æ‰€æœ‰å…¬ä¼—å·çš„æŠ“å–ç»“æœ
        all_results = []
        successful_count = 0
        failed_count = 0

        try:
            for i, target in enumerate(all_targets, 1):
                self.logger.info("="*60)
                self.logger.info(f"ğŸ“ å¤„ç†ç¬¬ {i}/{len(all_targets)} ä¸ªå…¬ä¼—å·: {target['name']}")
                self.logger.info("="*60)

                # ä¸ºæ¯ä¸ªå…¬ä¼—å·åˆ›å»ºç‹¬ç«‹çš„CookieæŠ“å–å™¨
                cookie_reader = None
                try:
                    # æ­¥éª¤1: ä¸ºæ¯ä¸ªå…¬ä¼—å·åˆ›å»ºç‹¬ç«‹çš„CookieæŠ“å–å™¨
                    self.logger.info(f"[æ­¥éª¤ 1/5] ä¸º '{target['name']}' åˆ›å»ºç‹¬ç«‹çš„ Cookie æŠ“å–å™¨...")
                    cookie_reader = ReadCookie()  # æ¯ä¸ªå…¬ä¼—å·ç‹¬ç«‹åˆ›å»ºï¼Œä¼šåˆ é™¤æ—§æ–‡ä»¶

                    if not cookie_reader.start_cookie_extractor():
                        self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' Cookie æŠ“å–å™¨å¯åŠ¨å¤±è´¥ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
                        failed_count += 1
                        continue
                    self.logger.info("âœ… Cookie æŠ“å–å™¨å·²åœ¨åå°è¿è¡Œã€‚")

                    # æ­¥éª¤2: è¿è¡Œ UI è‡ªåŠ¨åŒ–è§¦å‘æŠ“å–
                    self.logger.info(f"[æ­¥éª¤ 2/5] ä¸º '{target['name']}' å¯åŠ¨ UI è‡ªåŠ¨åŒ–...")
                    try:
                        ui_crawler = ExcelAutoCrawler()
                        # ç›´æ¥ä¼ é€’å½“å‰å…¬ä¼—å·çš„URLï¼Œå¹¶ä¼ é€’cookie_readerä»¥å¯ç”¨æ™ºèƒ½åˆ·æ–°åœæ­¢
                        success = ui_crawler.automation.send_and_open_latest_link(target['url'], cookie_reader=cookie_reader)
                        if not success:
                            self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' UI è‡ªåŠ¨åŒ–è§¦å‘å¤±è´¥ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
                            cookie_reader.stop_cookie_extractor()
                            failed_count += 1
                            continue
                    except Exception as e:
                        self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' UI è‡ªåŠ¨åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        cookie_reader.stop_cookie_extractor()
                        failed_count += 1
                        continue
                    self.logger.info("âœ… UI è‡ªåŠ¨åŒ–å·²æˆåŠŸè§¦å‘é“¾æ¥æ‰“å¼€ã€‚")

                    # æ­¥éª¤3: ç­‰å¾…å¹¶éªŒè¯ Cookie
                    self.logger.info(f"[æ­¥éª¤ 3/5] ç­‰å¾… '{target['name']}' çš„ Cookie æ•°æ®...")
                    if not cookie_reader.wait_for_new_cookie(timeout=120):
                        self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' ç­‰å¾… Cookie è¶…æ—¶ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
                        cookie_reader.stop_cookie_extractor()
                        failed_count += 1
                        continue

                    # éªŒè¯cookieæ˜¯å¦æœ‰æ•ˆ
                    auth_info = cookie_reader.get_latest_cookies()
                    if not auth_info:
                        self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' Cookie è§£æå¤±è´¥")
                        self.logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› :")
                        self.logger.error("   1. mitmproxy æ²¡æœ‰æˆåŠŸæŠ“å–åˆ°å¾®ä¿¡è¯·æ±‚")
                        self.logger.error("   2. å¾®ä¿¡å†…ç½®æµè§ˆå™¨æ²¡æœ‰æ­£ç¡®æ‰“å¼€é“¾æ¥")
                        self.logger.error("   3. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–ä»£ç†è®¾ç½®é—®é¢˜")
                        self.logger.error("ğŸ’¡ å»ºè®®:")
                        self.logger.error("   1. æ£€æŸ¥å¾®ä¿¡æ˜¯å¦æ­£å¸¸æ‰“å¼€äº†æ–‡ç« é“¾æ¥")
                        self.logger.error("   2. æ‰‹åŠ¨åœ¨å¾®ä¿¡ä¸­åˆ·æ–°æ–‡ç« é¡µé¢")
                        self.logger.error("   3. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
                        cookie_reader.stop_cookie_extractor()
                        failed_count += 1
                        continue
                    self.logger.info("âœ… æˆåŠŸè·å–å¹¶éªŒè¯äº†æ–°çš„ Cookieã€‚")

                    # æ­¥éª¤4: åœæ­¢ mitmproxy æŠ“å–å™¨
                    self.logger.info(f"[æ­¥éª¤ 4/5] åœæ­¢ '{target['name']}' çš„ Cookie æŠ“å–å™¨...")
                    cookie_reader.stop_cookie_extractor()
                    time.sleep(3)  # ç­‰å¾…ä»£ç†å®Œå…¨å…³é—­
                    self.logger.info("âœ… Cookie æŠ“å–å™¨å·²åœæ­¢ï¼Œç³»ç»Ÿä»£ç†å·²æ¢å¤ã€‚")

                    # æ­¥éª¤5: è¿è¡Œæ‰¹é‡çˆ¬è™«ï¼ˆå¸¦Cookieé‡æ–°æŠ“å–æœºåˆ¶ï¼‰
                    self.logger.info(f"[æ­¥éª¤ 5/5] å¼€å§‹çˆ¬å– '{target['name']}' çš„æ–‡ç« ...")

                    max_attempts = 2  # æœ€å¤šå°è¯•2æ¬¡ï¼ˆç¬¬ä¸€æ¬¡å¤±è´¥åé‡æ–°æŠ“å–Cookieå†è¯•ä¸€æ¬¡ï¼‰
                    batch_spider = None

                    for attempt in range(max_attempts):
                        try:
                            self.logger.info(f"ğŸ”„ ç¬¬ {attempt + 1}/{max_attempts} æ¬¡å°è¯•çˆ¬å–...")
                            batch_spider = BatchReadnumSpider(
                                auth_info=auth_info,
                                save_to_db=self.save_to_db,
                                db_config=self.db_config,
                                unit_name=target['name']
                            )

                            # å…ˆéªŒè¯Cookie
                            if not batch_spider.validate_cookie():
                                if attempt < max_attempts - 1:
                                    self.logger.warning("âš ï¸ CookieéªŒè¯å¤±è´¥ï¼ˆret=-3ï¼‰ï¼Œå‡†å¤‡é‡æ–°æŠ“å–Cookie...")

                                    # é‡æ–°æŠ“å–Cookie
                                    self.logger.info("ğŸ”„ é‡æ–°å¯åŠ¨CookieæŠ“å–å™¨...")
                                    fresh_cookie_reader = ReadCookie()
                                    if not fresh_cookie_reader.start_cookie_extractor():
                                        self.logger.error("âŒ é‡æ–°å¯åŠ¨CookieæŠ“å–å™¨å¤±è´¥")
                                        break

                                    # é‡æ–°è§¦å‘UIè‡ªåŠ¨åŒ–
                                    self.logger.info("ğŸ”„ é‡æ–°è§¦å‘UIè‡ªåŠ¨åŒ–...")
                                    ui_crawler = ExcelAutoCrawler()
                                    success = ui_crawler.automation.send_and_open_latest_link(target['url'], cookie_reader=fresh_cookie_reader)
                                    if not success:
                                        self.logger.error("âŒ é‡æ–°è§¦å‘UIè‡ªåŠ¨åŒ–å¤±è´¥")
                                        fresh_cookie_reader.stop_cookie_extractor()
                                        break

                                    # ç­‰å¾…æ–°Cookie
                                    if not fresh_cookie_reader.wait_for_new_cookie(timeout=120):
                                        self.logger.error("âŒ é‡æ–°ç­‰å¾…Cookieè¶…æ—¶")
                                        fresh_cookie_reader.stop_cookie_extractor()
                                        break

                                    # è·å–æ–°çš„è®¤è¯ä¿¡æ¯
                                    auth_info = fresh_cookie_reader.get_latest_cookies()
                                    fresh_cookie_reader.stop_cookie_extractor()
                                    time.sleep(3)

                                    if not auth_info:
                                        self.logger.error("âŒ é‡æ–°è·å–Cookieå¤±è´¥")
                                        break

                                    self.logger.info("âœ… æˆåŠŸé‡æ–°è·å–Cookieï¼Œç»§ç»­å°è¯•...")
                                    continue
                                else:
                                    self.logger.error("âŒ å¤šæ¬¡å°è¯•åCookieä»ç„¶æ— æ•ˆ")
                                    break

                            # Cookieæœ‰æ•ˆï¼Œå¼€å§‹æ­£å¼çˆ¬å–
                            self.logger.info("âœ… CookieéªŒè¯æˆåŠŸï¼Œå¼€å§‹æ­£å¼çˆ¬å–...")
                            batch_spider.batch_crawl_readnum()
                            break  # æˆåŠŸå®Œæˆï¼Œè·³å‡ºé‡è¯•å¾ªç¯

                        except Exception as e:
                            self.logger.error(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                            if attempt < max_attempts - 1:
                                self.logger.info("ğŸ”„ å‡†å¤‡é‡è¯•...")
                                time.sleep(5)
                            else:
                                self.logger.error("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")

                    if not batch_spider or not batch_spider.articles_data:
                        self.logger.error(f"âŒ å…¬ä¼—å· '{target['name']}' çˆ¬å–å¤±è´¥")
                        failed_count += 1
                        continue

                    if batch_spider.articles_data:
                        # ä¸ºæ¯ç¯‡æ–‡ç« æ·»åŠ å…¬ä¼—å·ä¿¡æ¯
                        for article in batch_spider.articles_data:
                            article['å…¬ä¼—å·åç§°'] = target['name']
                            article['å…¬ä¼—å·åºå·'] = i

                        all_results.extend(batch_spider.articles_data)

                        # ä¿å­˜å½“å‰å…¬ä¼—å·çš„æ•°æ®
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        excel_file = batch_spider.save_to_excel(f"./data/readnum_batch/readnum_{target['name']}_{timestamp}.xlsx")
                        json_file = batch_spider.save_to_json(f"./data/readnum_batch/readnum_{target['name']}_{timestamp}.json")

                        self.logger.info(f"âœ… å…¬ä¼—å· '{target['name']}' çˆ¬å–å®Œæˆï¼è·å– {len(batch_spider.articles_data)} ç¯‡æ–‡ç« ")
                        self.logger.info(f"ğŸ“Š æ•°æ®å·²ä¿å­˜åˆ°: {excel_file}")
                        successful_count += 1
                    else:
                        self.logger.warning(f"âš ï¸ å…¬ä¼—å· '{target['name']}' æœªè·å–åˆ°ä»»ä½•æ–‡ç« æ•°æ®")
                        failed_count += 1

                    # å…¬ä¼—å·é—´å»¶è¿Ÿï¼Œé¿å…é¢‘ç¹è¯·æ±‚
                    if i < len(all_targets):
                        delay_time = 15
                        self.logger.info(f"â³ å…¬ä¼—å·é—´å»¶è¿Ÿ {delay_time} ç§’...")
                        time.sleep(delay_time)

                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†å…¬ä¼—å· '{target['name']}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    # ç¡®ä¿åœæ­¢æŠ“å–å™¨
                    if cookie_reader:
                        try:
                            cookie_reader.stop_cookie_extractor()
                        except:
                            pass
                    failed_count += 1
                    continue

        except Exception as e:
            self.logger.error(f"âŒ è‡ªåŠ¨åŒ–æµç¨‹å‘ç”ŸæœªçŸ¥ä¸¥é‡é”™è¯¯: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False

        # æ±‡æ€»ç»“æœ
        self.logger.info("="*80)
        self.logger.info("ğŸ“Š å¤šå…¬ä¼—å·çˆ¬å–æ±‡æ€»ç»“æœ")
        self.logger.info("="*80)
        self.logger.info(f"âœ… æˆåŠŸå¤„ç†: {successful_count} ä¸ªå…¬ä¼—å·")
        self.logger.info(f"âŒ å¤±è´¥å¤„ç†: {failed_count} ä¸ªå…¬ä¼—å·")
        self.logger.info(f"ğŸ“„ æ€»è®¡æ–‡ç« : {len(all_results)} ç¯‡")

        # æ±‡æ€»æ•°æ®ä¿å­˜åŠŸèƒ½å·²ç§»é™¤

        self.logger.info("="*80)
        self.logger.info("âœ… å¤šå…¬ä¼—å·å…¨æ–°è‡ªåŠ¨åŒ–æµç¨‹æ‰§è¡Œå®Œæ¯• âœ…")
        self.logger.info("="*80)

        return successful_count > 0  # åªè¦æœ‰ä¸€ä¸ªæˆåŠŸå°±ç®—æˆåŠŸ
